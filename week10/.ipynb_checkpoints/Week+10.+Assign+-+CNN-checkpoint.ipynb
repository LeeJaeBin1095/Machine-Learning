{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10. Convolutional Neural Networks\n",
    "\n",
    "과제는 총 2개의 cell을 작성하도록 구성되어있습니다\n",
    "\n",
    "1~2 문제는 영상과 실습자료에 나와있는 것들을 적절히 응용하시면 됩니다\n",
    "\n",
    "주석의 경우 이미지, 테이블 등의 표현이 어려운 관계로 받지 않겠습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 01. Cifar 100 for Coarse labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset cifar 100을 dataset으로 사용하여 과제를 진행합니다\n",
    "\n",
    "Train set으로 학습하면서 validation으로 test를 사용해주세요\n",
    "\n",
    "Monitoring 용도로만 사용하며 학습에는 개입하지않습니다\n",
    "\n",
    "모델은 convolution layer를 사용하여 자유롭게 생성하시면 됩니다\n",
    "\n",
    "그리고 convolution layer의 일부분이 저장가능하도록 만들어주세요\n",
    "\n",
    "실습 02에서 fine labels로 transfer learning을 시도해보겠습니다\n",
    "\n",
    "생성한 모델로 coarse labels를 학습하고 성능과 loss가 학습하는 동안 어떻게 변했는지 시각화해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.offline import iplot,plot\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('10_train.npy')\n",
    "test = np.load('10_test.npy')\n",
    "train_labels = pd.read_csv('10_tr_labels.csv')\n",
    "test_labels = pd.read_csv('10_ts_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_super_dict = {i:n for n,i in enumerate(train_labels.coarse_labels.unique())}\n",
    "tr_sub_dict = {i:n for n,i in enumerate(train_labels.fine_labels.unique())}\n",
    "\n",
    "tr_super_y = train_labels['coarse_labels'].apply(lambda x: tr_super_dict[x]).values\n",
    "tr_sub_y = train_labels['fine_labels'].apply(lambda x: tr_sub_dict[x]).values\n",
    "\n",
    "ts_super_y = test_labels['coarse_labels'].apply(lambda x: tr_super_dict[x]).values\n",
    "ts_sub_y = test_labels['fine_labels'].apply(lambda x: tr_sub_dict[x]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_function():\n",
    "    input_layer = tf.keras.Input((32,32,3))\n",
    "    for n in range(3):\n",
    "        if n == 0:\n",
    "            conv = tf.keras.layers.Conv2D(filters=2**7,kernel_size=3,padding='same')(input_layer)\n",
    "        else:\n",
    "            conv = tf.keras.layers.Conv2D(filters=2**7,kernel_size=3,padding='same')(pool)\n",
    "        batch=tf.keras.layers.BatchNormalization()(conv)\n",
    "        activ=tf.keras.layers.Activation('relu')(batch)\n",
    "        pool=tf.keras.layers.MaxPool2D()(activ)\n",
    "        \n",
    "    return tf.keras.models.Model(input_layer, pool)\n",
    "model=shared_function()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "functional_7 (Functional)    (None, 4, 4, 128)         300288    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 6147      \n",
      "=================================================================\n",
      "Total params: 306,435\n",
      "Trainable params: 305,667\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 56s 1s/step - loss: 0.9310 - accuracy: 0.5809\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 56s 1s/step - loss: 0.7624 - accuracy: 0.6541\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 55s 1s/step - loss: 0.7097 - accuracy: 0.6880\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 57s 1s/step - loss: 0.6662 - accuracy: 0.7075\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 56s 1s/step - loss: 0.6089 - accuracy: 0.7397\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 54s 1s/step - loss: 0.5478 - accuracy: 0.7700\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.4744 - accuracy: 0.8168\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.4013 - accuracy: 0.8503\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 53s 1s/step - loss: 0.3655 - accuracy: 0.8623\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 63s 2s/step - loss: 0.2969 - accuracy: 0.9019\n"
     ]
    }
   ],
   "source": [
    "super_input_layer = tf.keras.Input((32,32,3))\n",
    "flat_layer=tf.keras.layers.Flatten()(model(super_input_layer))  # functional_1으로 표시됨 \n",
    "super_output_layer=tf.keras.layers.Dense(3, activation='softmax')(flat_layer)\n",
    "super_model=tf.keras.models.Model(super_input_layer, super_output_layer)\n",
    "super_model.compile('Adam','categorical_crossentropy','accuracy')\n",
    "history_super=super_model.fit(train,\n",
    "                             tf.keras.utils.to_categorical(tr_super_y),\n",
    "                             batch_size=200, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "super_model : 68.4%\n"
     ]
    }
   ],
   "source": [
    "print(f'super_model : {(super_model.predict(test).argmax(1)==ts_super_y).mean()*100:.5}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 epoch동안 학습한 결과 loss : 0.93, 정확도 : 0.58이 loss : 0.29, 정확도 : 0.90 까지 성능이 향상이 되었고 해당 모델로 테스트 한 결과 68.4%의 정확도가 나왔습니다. \n",
    "epoch를 더 높게 한다면 정확도가 더 높게 측정될것으로 생각됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 02. Cifar 100 for fine labels applied transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coarse labels로 학습된 모델을 저장한 뒤 transfer learning으로 fine label을 학습시켜보세요\n",
    "\n",
    "그리고 test set에 대해 loss와 성능이 어떻게 변하는지 시각화해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "load_model=tf.keras.models.load_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "functional_7 (Functional)    (None, 4, 4, 128)         300288    \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 15)                30735     \n",
      "=================================================================\n",
      "Total params: 331,023\n",
      "Trainable params: 330,255\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 55s 1s/step - loss: 2.1658 - accuracy: 0.3052\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 55s 1s/step - loss: 1.6509 - accuracy: 0.4587\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 55s 1s/step - loss: 1.4062 - accuracy: 0.5407\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 55s 1s/step - loss: 1.2161 - accuracy: 0.6060\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 58s 2s/step - loss: 1.0532 - accuracy: 0.6652\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 55s 1s/step - loss: 0.8810 - accuracy: 0.7316\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 57s 1s/step - loss: 0.7544 - accuracy: 0.7708\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 56s 1s/step - loss: 0.6100 - accuracy: 0.8319\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 55s 1s/step - loss: 0.4961 - accuracy: 0.8771\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 57s 2s/step - loss: 0.3923 - accuracy: 0.9207\n"
     ]
    }
   ],
   "source": [
    "load_input_layer = tf.keras.Input((32,32,3))\n",
    "flat_layer=tf.keras.layers.Flatten()(load_model(load_input_layer))  \n",
    "load_output_layer=tf.keras.layers.Dense(15, activation='softmax')(flat_layer)\n",
    "load_super_model=tf.keras.models.Model(load_input_layer, load_output_layer)\n",
    "load_super_model.summary()\n",
    "load_super_model.compile('Adam','categorical_crossentropy','accuracy')\n",
    "history_super=load_super_model.fit(train,\n",
    "                                   tf.keras.utils.to_categorical(tr_sub_y),\n",
    "                                   batch_size=200, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_model : 34.467%\n"
     ]
    }
   ],
   "source": [
    "print(f'sub_model : {(load_super_model.predict(test).argmax(1)==ts_sub_y).mean()*100:.5}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10번의 학습 결과 loss : 2.16, 정확도 : 0.3에서 loss 0.39, 정확도 0.92로 실습1에 비해서 정확도가 0.02정도 높게 측정이 되었지만 테스트 결과에서 더 안좋게 측정이 되었습니다. epoch를 좀더 높게 한다면 더 나은 결과가 나올것이라 생각합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
