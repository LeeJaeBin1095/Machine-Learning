{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 08. Multi Layer Perceptron\n",
    "\n",
    "과제는 총 3개의 cell을 작성하도록 구성되어있습니다\n",
    "\n",
    "1~3 문제는 영상과 실습자료에 나와있는 것들을 적절히 응용하시면 됩니다\n",
    "\n",
    "주석의 경우 이미지, 테이블 등의 표현이 어려운 관계로 받지 않겠습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 00. Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset covertype이며, 인공위성이 찍은 사진을 전처리하여 table data로 작성한 dataset입니다\n",
    "\n",
    "train set으로 다양한 방법들을 교차검증하고, test set에서도 좋은 성능을 보이는지 확인해보겠습니다\n",
    "\n",
    "train set과 test set을 불러와주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly import graph_objs as go\n",
    "\n",
    "x_train=pd.read_csv('08_mlp_x_train.csv')\n",
    "x_test=pd.read_csv('08_mlp_x_test.csv')\n",
    "y_train=pd.read_csv('08_mlp_y_train.csv')\n",
    "y_test=pd.read_csv('08_mlp_y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 01. K-Fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train set으로부터 학습된 모델은 test set을 잘 예측해야 하는 목표를 갖고 있습니다\n",
    "\n",
    "test을 잘 예측하기 위해 각 방법별로 교차검증을 시도하겠습니다\n",
    "\n",
    "모든 train sample들에 평균적으로 가장 좋은 성능을 보이는 모델을 찾아보려합니다\n",
    "\n",
    "다음 방법들을 5-Fold를 사용하여 교차검증해주세요\n",
    "\n",
    "그리고 실제 test set에 대해 성능을 마지막으로 출력해주세요\n",
    "\n",
    "사용할 분류 기법 : Gaussian Naive-bayes, k-Neighbors Nearest, Decision Tree, Random Forest, Logistics regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB의 평균 정확도 :             71.505%, 정확도의 편차 : 0.0043542\n",
      "KNeighborsClassifier의 평균 정확도 :   97.262%, 정확도의 편차 : 0.0015133\n",
      "DecisionTreeClassifier의 평균 정확도 : 93.865%, 정확도의 편차 : 0.0040876\n",
      "RandomForestClassifier의 평균 정확도 : 95.767%, 정확도의 편차 : 0.0018389\n",
      "LogisticRegression의 평균 정확도 :     72.548%, 정확도의 편차 : 0.0059377\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "scores_GNB = []\n",
    "GNB = GaussianNB()\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    x_tr, x_te, y_tr, y_te = \\\n",
    "    x_train.iloc[train_index], x_train.iloc[test_index], y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    GNB.fit(x_tr, y_tr.values.ravel())\n",
    "    scores_GNB.append(GNB.score(x_te, y_te.values.ravel()))\n",
    "\n",
    "scores_kNN = []\n",
    "kNN = KNeighborsClassifier()\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    x_tr, x_te, y_tr, y_te = \\\n",
    "    x_train.iloc[train_index], x_train.iloc[test_index], y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    kNN.fit(x_tr, y_tr.values.ravel())\n",
    "    scores_kNN.append(kNN.score(x_te, y_te.values.ravel()))\n",
    "\n",
    "scores_DT = []\n",
    "DT = DecisionTreeClassifier()\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    x_tr, x_te, y_tr, y_te = \\\n",
    "    x_train.iloc[train_index], x_train.iloc[test_index], y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    DT.fit(x_tr, y_tr.values.ravel())\n",
    "    scores_DT.append(DT.score(x_te, y_te.values.ravel()))\n",
    "\n",
    "scores_RF = []\n",
    "RF = RandomForestClassifier()\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    x_tr, x_te, y_tr, y_te = \\\n",
    "    x_train.iloc[train_index], x_train.iloc[test_index], y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    RF.fit(x_tr, y_tr.values.ravel())\n",
    "    scores_RF.append(RF.score(x_te, y_te.values.ravel()))\n",
    "    \n",
    "\n",
    "scores_LR = []\n",
    "logistic = LogisticRegression()\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    x_tr, x_te, y_tr, y_te = \\\n",
    "    x_train.iloc[train_index], x_train.iloc[test_index], y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    logistic.fit(x_tr, y_tr.values.ravel())\n",
    "    scores_LR.append(logistic.score(x_te, y_te.values.ravel()))\n",
    "    \n",
    "    \n",
    "print(f'GaussianNB의 평균 정확도 :             {np.array(scores_GNB).mean()*100:.5}%, 정확도의 편차 : {np.array(scores_GNB).std():.5}')\n",
    "print(f'KNeighborsClassifier의 평균 정확도 :   {np.array(scores_kNN).mean()*100:.5}%, 정확도의 편차 : {np.array(scores_kNN).std():.5}')\n",
    "print(f'DecisionTreeClassifier의 평균 정확도 : {np.array(scores_DT).mean()*100:.5}%, 정확도의 편차 : {np.array(scores_DT).std():.5}')\n",
    "print(f'RandomForestClassifier의 평균 정확도 : {np.array(scores_RF).mean()*100:.5}%, 정확도의 편차 : {np.array(scores_RF).std():.5}')\n",
    "print(f'LogisticRegression의 평균 정확도 :     {np.array(scores_LR).mean()*100:.5}%, 정확도의 편차 : {np.array(scores_LR).std():.5}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB의 test 정확도 :             71.888%\n",
      "KNeighborsClassifier의 test 정확도 :   97.063%\n",
      "DecisionTreeClassifier의 test 정확도 : 93.698%\n",
      "RandomForestClassifier의 test 정확도 : 95.753%\n",
      "LogisticRegression의 test 정확도 :     72.34%\n"
     ]
    }
   ],
   "source": [
    "print(f'GaussianNB의 test 정확도 :             {GNB.score(x_test, y_test.values.ravel())*100:.5}%')\n",
    "print(f'KNeighborsClassifier의 test 정확도 :   {kNN.score(x_test, y_test.values.ravel())*100:.5}%')\n",
    "print(f'DecisionTreeClassifier의 test 정확도 : {DT.score(x_test, y_test.values.ravel())*100:.5}%')\n",
    "print(f'RandomForestClassifier의 test 정확도 : {RF.score(x_test, y_test.values.ravel())*100:.5}%')\n",
    "print(f'LogisticRegression의 test 정확도 :     {logistic.score(x_test, y_test.values.ravel())*100:.5}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습 결과 모델들의 5-Fold 평균 정확도와 test 정확도간의 큰차이는 보이지 않는것을 확인할 수 있었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 02. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP는 perceptron들을 다양한 구조로 엮어놓은 모델입니다\n",
    "\n",
    "Perceptron의 layer 갯수와 각 층마다 존재하는 perceptorn의 갯수, perceptron의 output을 변형하는 함수등이 모델성능을 결정합니다\n",
    "\n",
    "실습영상에서는 perceptron의 층수만 바꿔가며 간단하게 실험하였지만 과제로 다양한 MLP 모델을 시도해보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 02-1. Multi Layer Perceptron - The number of perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perceptron의 갯수를 감소시켜가며 확인해보겠습니다\n",
    "\n",
    "2개의 perceptron layer를 사용하면서 50개, 20개일때로 층별 perceptron의 숫자를 줄여보세요\n",
    "\n",
    "그리고 2개의 모델을 5-fold로 교차검증하여 아래 결과를 제시해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6946013101423085, 0.7081545064377682, 0.5742686095109003, 0.7141082119055687, 0.6534508076358296]\n",
      "MLP50 평균 정확도 : 66.892%, 정확도의 편차 : 0.0518\n",
      "Wall time: 52.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlp50 = MLPClassifier((50,50),\n",
    "                   activation = 'identity',\n",
    "                   max_iter = 200,\n",
    "                   n_iter_no_change = 10,\n",
    "                   )\n",
    "\n",
    "scores_50 = []\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    x_tr, x_te, y_tr, y_te = \\\n",
    "    x_train.iloc[train_index], x_train.iloc[test_index], y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    mlp50.fit(x_tr, y_tr.values.ravel())\n",
    "    scores_50.append(mlp50.score(x_te, y_te.values.ravel()))\n",
    "print(scores_50)\n",
    "print(f'MLP50 평균 정확도 : {np.array(scores_50).mean()*100:.5}%, 정확도의 편차 : {np.array(scores_50).std():.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7370679918680823, 0.7489270386266095, 0.7136563876651982, 0.7379419405851124, 0.7111713543431605]\n",
      "MLP20 평균 정확도 : 72.975%, 정확도의 편차 : 0.0148\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlp20 = MLPClassifier((20,20),\n",
    "                   activation = 'identity',\n",
    "                   max_iter = 200,\n",
    "                   n_iter_no_change = 10,\n",
    "                   )\n",
    "\n",
    "scores_20 = []\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    x_tr, x_te, y_tr, y_te = \\\n",
    "    x_train.iloc[train_index], x_train.iloc[test_index], y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    mlp20.fit(x_tr, y_tr.values.ravel())\n",
    "    scores_20.append(mlp20.score(x_te, y_te.values.ravel()))\n",
    "    \n",
    "print(scores_20)\n",
    "print(f'MLP20 평균 정확도 : {np.array(scores_20).mean()*100:.5}%, 정확도의 편차 : {np.array(scores_20).std():.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습 결과화면에서는 perceptron 갯수가 20개인 것이 시간과 정확도 면에서 좋게 평가되었는데 여러번 돌려보니  \n",
    "perceptron 갯수가 50개인 것이 정확도면에서 좋게 평가되는 경우도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 02-1. Multi Layer Perceptron - Various output function for every perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습 영상에서 사용한 MLP는 각 perceptron output function으로 $f(x)=x$의 관계인 linear output을 사용하고 있습니다\n",
    "\n",
    "이번에는 linear output을 바꿔 sigmoid를 사용해보겠습니다\n",
    "\n",
    "MLP classifier의 activations parameter를 'identity'에서 'logistic' 또는 'tanh'로 바꿔주세요\n",
    "\n",
    "그리고 실습 02-1.의 과정을 반복하여 결과를 제시해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7875536480686696, 0.7702733227919585, 0.7565796905003953, 0.7775895176776234, 0.7789449903987349]\n",
      "MLP50 평균 정확도 : 77.419%, 정확도의 편차 : 0.0104\n",
      "Wall time: 58.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlp50 = MLPClassifier((50,50),\n",
    "                   activation = 'logistic',\n",
    "                   max_iter = 200,\n",
    "                   n_iter_no_change = 10,\n",
    "                   )\n",
    "\n",
    "scores_50 = []\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    x_tr, x_te, y_tr, y_te = \\\n",
    "    x_train.iloc[train_index], x_train.iloc[test_index], y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    mlp50.fit(x_tr, y_tr.values.ravel())\n",
    "    scores_50.append(mlp50.score(x_te, y_te.values.ravel()))\n",
    "\n",
    "print(scores_50)\n",
    "print(f'MLP50 평균 정확도 : {np.array(scores_50).mean()*100:.5}%, 정확도의 편차 : {np.array(scores_50).std():.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7697086062796477, 0.7284843008809577, 0.7394103693663165, 0.7292443239579803, 0.7583869874618774]\n",
      "MLP20 평균 정확도 : 74.505%, 정확도의 편차 : 0.0164\n",
      "Wall time: 45.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlp20 = MLPClassifier((20,20),\n",
    "                   activation = 'logistic',\n",
    "                   max_iter = 200,\n",
    "                   n_iter_no_change = 10,\n",
    "                   )\n",
    "\n",
    "scores_20 = []\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    x_tr, x_te, y_tr, y_te = \\\n",
    "    x_train.iloc[train_index], x_train.iloc[test_index], y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    mlp20.fit(x_tr, y_tr.values.ravel())\n",
    "    scores_20.append(mlp20.score(x_te, y_te.values.ravel()))\n",
    "\n",
    "print(scores_20)\n",
    "print(f'MLP20 평균 정확도 : {np.array(scores_20).mean()*100:.5}%, 정확도의 편차 : {np.array(scores_20).std():.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic으로 변경하고 나서 실습한 결과 두 모델 전부 정확도와 편차가 어느 정도 개선된 것으로 보여진다.  \n",
    "특히 perceptron 50 모델은 정확도가 11%정도 상승했다.  \n",
    "시간같은 경우 perceptron 50 모델은 차이가 별루 없지만 perceptron 20 모델은 2배 정도 증가했다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
