{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 8. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기계학습 8주차는 세가지 목표가 있다.\n",
    "1. sigmoid with regression & k-fold validation\n",
    "2. Perceptron\n",
    "3. Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 실습은 다시 분류 문제를 해결한다.  \n",
    "이번 주는 먼저 회귀방법으로 분류 문제를 푸는 기법을 소개하겠다.  \n",
    "dataset covertype이며 인공위성이 찍은 사진을 전처리하여 table data로 작성한 데이터셋이다.  \n",
    "4.4만개의 instance가 54의 feature을 가지고 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44267, 54), (44267, 1))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "x = pd.read_csv('08_mlp_x_train.csv')\n",
    "y = pd.read_csv('08_mlp_y_train.csv')\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression은 linear regression method를 분류 문제에 적용한 방법이다.  \n",
    "Regression 모델의 output은 continous value이다.  \n",
    "continous value를 분류문제로 적용하기 위해 output이 특수한 함수를 거치도록 설계되었다.  \n",
    "함수 sigmoid는 continuous value를 0 ~ 1 사이의 probability로 변환시켜준다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 평가를 위해 이번 실습부터 K-fold를 사용하겠다.  \n",
    "K-fold는 train set을 k등분하여 교차검증하는 방법이다.  \n",
    "트레이닝 셋을 k개의 Fold를 나눠서 그중 1개씩 뽑아서 k번 split돌려서 학습시킨다.  \n",
    "\n",
    "Train data중 일부만 추출해내어 model의 성능을 평가하는 것은 추출된 sample에 따라 편향될 가능성이 존재한다.  \n",
    "K-Fold는 모든 train sample에 대해 예측하고 성능을 평가했기 대문에 model성능의 일관성 또한 확인할 수 있다.  \n",
    "때문에 모든 train sample을 설명할 수 있는 model을 만든다면 test data도 잘 예측할 수 있다는 기대를 할 수 있다.  \n",
    "안정된 모델을 만든다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44267 44267\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(shuffle = True)\n",
    "\n",
    "test_index_set = set()  # set 타입은 중복된 값이 들어갈 수 없다.  \n",
    "\n",
    "for train_index, test_index in kf.split(x,y):\n",
    "    test_index_set.update(test_index)\n",
    "    \n",
    "print(len(test_index_set), x.shape[0])   # 테스트 셋을 전부 교차 검증한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Logistic regression을 5 fold로 교차검증하겠다.  \n",
    "기존 학습에 걸리던 시간보다 K배의 시간이 들지만 모델 성능을 범용적으로 평가할 수 있다.  \n",
    "지금부터 코드 결과가 느리게 나온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 정확도 : 72.517%, 정확도의 편차 : 0.00518\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "scores = []\n",
    "logistic = LogisticRegression(max_iter = 100)\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    x_train, x_test, y_train, y_test = \\\n",
    "    x.iloc[train_index], x.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    logistic.fit(x_train, y_train.values.ravel())\n",
    "    scores.append(logistic.score(x_test, y_test.values.ravel()))\n",
    "\n",
    "print(f'평균 정확도 : {np.array(scores).mean()*100:.5}%, 정확도의 편차 : {np.array(scores).std():.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 선형회귀를 위해 coefficients 베타 또는 weights w를 계산하였다.  \n",
    "미분방정식을 풀어 error를 최소화하는 w를 찾았고 구한 w는 어느정도 실제 target을 설명할 수 있다.  \n",
    "Perceptron은 w를 수학적 해로 구하는 것이 아니라 error를 최소화 하도록 반복하여 개선시키는 방법이다.  \n",
    "두 클래스를 양분하는 선을 찾기위해 반복해가며 error를 최소화 하는 방향으로 w를 개선시킨다.  \n",
    "이 때문에 시간이 많이 걸린다.  \n",
    "\n",
    "현재의 w를 사용하여 data를 입력했을 때 예측하는 과정을 feed - forward라고 한다.  \n",
    "그리고 실제 y와 예측된 Y^의 차를 가지고 weights w를 업데이트 하는 과정을 back - propagation이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6796927942173029, 0.6773209848655974, 0.7173839376482548, 0.6962611544109342, 0.6523212470349035]\n",
      "평균 정확도 : 68.46%, 정확도의 편차 : 0.0216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "percep = Perceptron(n_jobs = -1, eta0 = 0.0001,   # wegiht를 얼마만큼 바꿀건지, 작게하면 에러를 100만큼 발생했지만 1만큼만 반영함\n",
    "                                                    # 델타 t를 점진적으로 증가시킴 \n",
    "                   max_iter = 10000,\n",
    "                    # verbose = 1,  # 과정 보이게 하는거 \n",
    "                   tol = 1e-5, n_iter_no_change = 100)\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(x,y):\n",
    "    x_train, x_test, y_train, y_test = \\\n",
    "    x.iloc[train_index], x.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    percep.fit(x_train, y_train.values.ravel())\n",
    "    scores.append(percep.score(x_test, y_test.values.ravel()))\n",
    "print(scores)\n",
    "print(f'평균 정확도 : {np.array(scores).mean()*100:.5}%, 정확도의 편차 : {np.array(scores).std():.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "복잡한 dimension을 관통하는 경계를 제안하여 두 class를 양분한다는건 어려운 일이다.  \n",
    "수학적인 해를 구하는 것 뿐만 아니라 error를 반영하여 개선하는 방법도 기계학습 방법 중 하나로 사용할 수 있음을 boosting 실습때 확인했다.  \n",
    "그런데 perceptron은 error를 개선하는데 한계에 부딧혀 test set을 분류하는 정확도를 일정 이상 개선하지 못했다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP는 perceptron을 병렬화, 복층화하여 만든 모델이다.  \n",
    "여러 perceptron을 동시에 개선하며, 복층 구조로 인해 XOR문제를 해결할 수 있게 되었다.  \n",
    "하나의 perceptron을 사용할경우 XOR문제와 더 복잡한 data를 분리하는 선을 그을수없지만   \n",
    "perceptron output들을 모아 다시한번 perceptron을 구성함으로써 XOR문제를 해결할 수 있게 된다.  \n",
    "그리고 Layer의 깊이가 더 깊어질수록 다양한 경계를 그을 수 있다고 설명한다.  \n",
    "이번과제는 시간이 너무 오래걸리니까 시각화에 압박감을 느끼지 말아달라 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6752880054212785, 0.7367291619606957, 0.6916299559471366, 0.7499152829549305, 0.7184005421890884]\n",
      "평균 정확도 : 71.439%, 정확도의 편차 : 0.0277\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier((100,),\n",
    "                   activation = 'identity',\n",
    "                   max_iter = 200,\n",
    "                   n_iter_no_change = 10,\n",
    "                   )\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    x_train, x_test, y_train, y_test = \\\n",
    "    x.iloc[train_index], x.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    mlp.fit(x_train, y_train.values.ravel())\n",
    "    scores.append(mlp.score(x_test, y_test.values.ravel()))\n",
    "print(scores)\n",
    "print(f'평균 정확도 : {np.array(scores).mean()*100:.5}%, 정확도의 편차 : {np.array(scores).std():.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7371809351705444, 0.7254348317144793, 0.7272111148763131, 0.7059753755788998, 0.6340223652998983]\n",
      "평균 정확도 : 70.596%, 정확도의 편차 : 0.0374\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier((100,100),\n",
    "                   activation = 'identity',\n",
    "                   max_iter = 200,\n",
    "                   n_iter_no_change = 10,\n",
    "                   )\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    x_train, x_test, y_train, y_test = \\\n",
    "    x.iloc[train_index], x.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    mlp.fit(x_train, y_train.values.ravel())\n",
    "    scores.append(mlp.score(x_test, y_test.values.ravel()))\n",
    "print(scores)\n",
    "print(f'평균 정확도 : {np.array(scores).mean()*100:.5}%, 정확도의 편차 : {np.array(scores).std():.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7026202846171222, 0.7339055793991416, 0.7247260815542754, 0.7468654693324297, 0.7197560149101999]\n",
      "평균 정확도 : 72.557%, 정확도의 편차 : 0.0147\n",
      "Wall time: 59.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier((100,100,100),\n",
    "                   activation = 'identity',\n",
    "                   max_iter = 200,\n",
    "                   n_iter_no_change = 10,\n",
    "                   )\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    x_train, x_test, y_train, y_test = \\\n",
    "    x.iloc[train_index], x.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    mlp.fit(x_train, y_train.values.ravel())\n",
    "    scores.append(mlp.score(x_test, y_test.values.ravel()))\n",
    "print(scores)\n",
    "print(f'평균 정확도 : {np.array(scores).mean()*100:.5}%, 정확도의 편차 : {np.array(scores).std():.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "층이 깊어질수록 다양한 경계를 생성할 수 있게된다.  \n",
    "또한 시간도 줄어즈는것을 보게 되었다. \n",
    "제시된 경계가 세밀해짐에 따라 모델의 성능이 향상되지만 overfit을 발생시킨다. \n",
    "Overfit으로 인해 우리가 모델을 적용하기 원하는 test set에 대해서 성능이 나빠질수있다.  \n",
    "또한 overfit과 별개로 학습시간이 증가하기 때문에 perceptron의 갯수를 무조껀 늘리는 것은 바람직하지 않다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형 회귀를 사용한 분류 기법 logistics regression을 실습하였다.  \n",
    "기법은 선형회귀의 출력값을 function sigmoid에 통과시켜 확률 output을 갖도록 변형시켰고 분류 문제에 풀수있도록 고안됬다. \n",
    "error를 최소화하는 베타를 계산하여 sample들을 성공적으로 분류했다.  \n",
    "반대로 베타를 무작위로 생성한 뒤 iterative하게 개선시키는 perceptron도 실습하였다.  \n",
    "perceptron은 y^과 y의 차이를 줄여나가 y^가 y와 일치하도록 W를 개선하였다.  \n",
    "하지만 XOR문제를 해결할수없었고 점진적으로 개선한 w가 최적의 w여부는 장담할수없었다.  \n",
    "MLP의 층이 늘어날수록 다양한 경계를 제시할 수 있다.  \n",
    "하지만 다양한 경계는 overfit을 불러일으키며 층이 늘어날수록 학습시간 또한 증가하였다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
