{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 9. Deep Forward Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기계학습 9주차는 두가지 목표로 구성된다.  \n",
    "1. Tensorflow를 사용하여 목적에 맞는 모델을 생성할 수 있다.  \n",
    "2. Tensorflow를 사용하여 Deep Forward Network를 학습할 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset covertype이며 인공위성이 찍은 사진을 전처리하여 table data로 작성한 dataset이다.  \n",
    "데이터를 불러오면 45000여개의 instance가 54개의 feature를 갖고 있는 것을 확인할 수 있다.  \n",
    "그리고 class는 총 3개를 갖고 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35527, 54) (35527, 1)\n",
      "[1 2 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "x = pd.read_csv('09_DFN_x_train.csv')\n",
    "y = pd.read_csv('09_DFN_y_train.csv')\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "print(y.iloc[:,0].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35522</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35523</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35524</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35525</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35526</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35527 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       54\n",
       "0       1\n",
       "1       2\n",
       "2       1\n",
       "3       2\n",
       "4       2\n",
       "...    ..\n",
       "35522   2\n",
       "35523   0\n",
       "35524   2\n",
       "35525   0\n",
       "35526   2\n",
       "\n",
       "[35527 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow는 인공신경망을 학습시키기 위해 설계된 Library이다.  \n",
    "인경신경망은 Graph구조에 기반을 두었고, node와 edge를 사용하는 다양한 연산들을 수행하기 위해 고안되었다.  \n",
    "보다 빠른 연산을 위해 cpu version외에도 gpu version을 지원한다.  \n",
    "수업시간에는 cpu를사용하겠다.  \n",
    "만약 gpu version을 적절하게 설치했다면 아래 명령어로 GPU사용여부를 확인할수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.config.get_visible_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"   ## gpu 사용을 중지함\n",
    "tf.config.get_visible_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 Tensorflow의 구조는 MLP와 같다.  \n",
    "perceptron을 계층화하여 층 하나를 쌓은 단위를 layer라고 부른다.  \n",
    "layer의 unit갯수를 조절하여 계층화된 perceptron의 층 별 갯수를 조절가능하다.  \n",
    "아래처럼 dense layer를 통과할 입력은 keras input으로 사용가능하다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.Input(3)\n",
    "dense_layer = tf.keras.layers.Dense(units=4)(input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi layer perceptron은 계층마다 비선형 output을 부여하여 특징추출을 가능하게 한다.  \n",
    "Dense layer의 output을 그대로 다음 계층의 dense layer로 전달한다면 특징 추출이 불가능하다.  \n",
    "따라서 dense layer의 output을 activation function에 통과시켜 비선형성을 부여하겠다.  (ReLU)   \n",
    "우리는 가장 기본적인 activation function sigmoid를 사용하겠다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_fn = tf.keras.activations.sigmoid(dense_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 과정을 이어 구조를 생성하고 구조를 확인하겠다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = tf.keras.layers.Dense(units=4)(activation_fn)\n",
    "activation_fn = tf.keras.activations.sigmoid(dense_layer)\n",
    "output_layer = tf.keras.layers.Dense(units=1)(activation_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "model = tf.keras.models.Model(input_layer, output_layer)\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.Input(3))\n",
    "model.add(tf.keras.layers.Dense(units=4, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(units=4, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "둘중 편한것을 사용하는 걸 추천하고 실습에서는 functional을 사용한다 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.02 Architecture - Batch normalization & drop out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural neys은 error를 반복적으로 개선하는만큼 overfit 성향이 강한 모델이다.  \n",
    "Overfit을 방지하기 위해 다양한 방법들이 있다.  \n",
    "batchnormalization은 각 층의 출력값을 평균 0, 표준편차를 1로 만들어준다.  \n",
    "drop out은 무작위로 edge를 0으로 만들어 일부 edge에 모델이 편향되는 현상을 방지한다.  \n",
    "다음은 두가지 방법을 적용한 모델이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.Input(3))\n",
    "model.add(tf.keras.layers.Dense(units=4))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "model.add(tf.keras.layers.Dropout(.3))\n",
    "model.add(tf.keras.layers.Dense(units=4))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "model.add(tf.keras.layers.Dropout(.3))\n",
    "model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.03 Architecture - Output node & Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function은 architecture와 긴밀한 연관성이 있다.  \n",
    "회귀문제의 경우 mean squared error, mean absolurer error를 사용하여 학습한다.  \n",
    "Architecture의 output이 linear이기 때문에 두 손실 함수로 충분히 학습할 수 있다.  \n",
    "차원을 하나만 사용한 분류의 경우 numerical class를 예측하는 만큼 회귀처럼 학습할 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Learning deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번엔 보다 깊은 모델을 생성하게다.  \n",
    "반복문을 사용하여 간단하게 5layer의 network를 생성하겠다.  \n",
    "layer마다 50개의 perceptron으로 구성하겠다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 54)]              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 30)                1650      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Tanh (TensorFlow [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Tanh_1 (TensorFl [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Tanh_2 (TensorFl [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 93        \n",
      "=================================================================\n",
      "Total params: 3,963\n",
      "Trainable params: 3,783\n",
      "Non-trainable params: 180\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    \n",
    "    input_layer = tf.keras.Input(x.shape[1])\n",
    "    \n",
    "    for n in range(3):\n",
    "        if n==0:\n",
    "            output = input_layer\n",
    "        else:\n",
    "            output = drop_layer\n",
    "            \n",
    "        dense_layer = tf.keras.layers.Dense(units=30)(output)\n",
    "        batch_layer = tf.keras.layers.BatchNormalization()(dense_layer)\n",
    "        activation_fn = tf.keras.activations.tanh(batch_layer)\n",
    "        drop_layer = tf.keras.layers.Dropout(.3)(activation_fn)\n",
    "        \n",
    "    output_layer = tf.keras.layers.Dense(units=3, activation='softmax')(drop_layer)\n",
    "    \n",
    "    return tf.keras.models.Model(input_layer, output_layer)\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "맨처음에 input할때 54+1(bias)해줘서 55*50 = 2750이 나오는것이다.  \n",
    "Tensorflow model은 학습하기 전 compile을 실행한다.  \n",
    "Model.compile로 실행할 수 있으며 적절한 argument를 사용하여 모델을 컴파일링하겠다.  \n",
    "옵티마이저와 loss는 반드시 체워줘야하고 metrics는 필수는 아니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss = 'binary_crossentropy',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network의 장점은 dataset size의 영향을 덜 받으면서 일반화할 수 있다는 점이다.  \n",
    "과도한 capacity의 neural net을 사용하더라도 충분히 잘 학습한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.6320 - accuracy: 0.4130\n",
      "Epoch 2/10\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.6294 - accuracy: 0.4172\n",
      "Epoch 3/10\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.6300 - accuracy: 0.4116\n",
      "Epoch 4/10\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.6303 - accuracy: 0.4124\n",
      "Epoch 5/10\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.6295 - accuracy: 0.4157\n",
      "Epoch 6/10\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.6283 - accuracy: 0.4170\n",
      "Epoch 7/10\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.6267 - accuracy: 0.4199\n",
      "Epoch 8/10\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.6262 - accuracy: 0.4167\n",
      "Epoch 9/10\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.6267 - accuracy: 0.4172\n",
      "Epoch 10/10\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.6257 - accuracy: 0.4195\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv('09_DFN_x_train.csv')\n",
    "y = pd.read_csv('09_DFN_y_train.csv')\n",
    "\n",
    "y = tf.keras.utils.to_categorical(y) # 원핫인코딩을 적용함\n",
    "history=model.fit(x,y,\n",
    "                 batch_size=200,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterative learning의 특징에 따라 학습이 진행될수록 training set은 잘 설명할 수 있다.  \n",
    "하지만 test set을 잘분류하는것이 중요한 만큼 training set을 적당히 학습해야한다.  \n",
    "이번에는 validation set을 준비해 학습하겠다.  \n",
    "실습에서는 train test split을 사용하지만 과제에는 k-fold를 사용해라  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.6591 - accuracy: 0.4015 - val_loss: 0.6144 - val_accuracy: 0.4330\n",
      "Epoch 2/1000\n",
      "134/134 [==============================] - 1s 5ms/step - loss: 0.6479 - accuracy: 0.3985 - val_loss: 0.6140 - val_accuracy: 0.4330\n",
      "Epoch 3/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6454 - accuracy: 0.4057 - val_loss: 0.6137 - val_accuracy: 0.4330\n",
      "Epoch 4/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6424 - accuracy: 0.4086 - val_loss: 0.6134 - val_accuracy: 0.4330\n",
      "Epoch 5/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6429 - accuracy: 0.4039 - val_loss: 0.6130 - val_accuracy: 0.4330\n",
      "Epoch 6/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6424 - accuracy: 0.4024 - val_loss: 0.6127 - val_accuracy: 0.4330\n",
      "Epoch 7/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6408 - accuracy: 0.4053 - val_loss: 0.6124 - val_accuracy: 0.4330\n",
      "Epoch 8/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6399 - accuracy: 0.4081 - val_loss: 0.6122 - val_accuracy: 0.4330\n",
      "Epoch 9/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6377 - accuracy: 0.4135 - val_loss: 0.6120 - val_accuracy: 0.4330\n",
      "Epoch 10/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6377 - accuracy: 0.4098 - val_loss: 0.6117 - val_accuracy: 0.4330\n",
      "Epoch 11/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6385 - accuracy: 0.4071 - val_loss: 0.6115 - val_accuracy: 0.4330\n",
      "Epoch 12/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6366 - accuracy: 0.4080 - val_loss: 0.6113 - val_accuracy: 0.4330\n",
      "Epoch 13/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6354 - accuracy: 0.4140 - val_loss: 0.6112 - val_accuracy: 0.4330\n",
      "Epoch 14/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6346 - accuracy: 0.4119 - val_loss: 0.6110 - val_accuracy: 0.4330\n",
      "Epoch 15/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6339 - accuracy: 0.4118 - val_loss: 0.6108 - val_accuracy: 0.4330\n",
      "Epoch 16/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6328 - accuracy: 0.4130 - val_loss: 0.6106 - val_accuracy: 0.4330\n",
      "Epoch 17/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6337 - accuracy: 0.4100 - val_loss: 0.6104 - val_accuracy: 0.4330\n",
      "Epoch 18/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6324 - accuracy: 0.4125 - val_loss: 0.6103 - val_accuracy: 0.4330\n",
      "Epoch 19/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6321 - accuracy: 0.4131 - val_loss: 0.6102 - val_accuracy: 0.4330\n",
      "Epoch 20/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6305 - accuracy: 0.4121 - val_loss: 0.6100 - val_accuracy: 0.4330\n",
      "Epoch 21/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6317 - accuracy: 0.4110 - val_loss: 0.6099 - val_accuracy: 0.4330\n",
      "Epoch 22/1000\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6294 - accuracy: 0.4168 - val_loss: 0.6097 - val_accuracy: 0.4330\n",
      "Epoch 23/1000\n",
      " 56/134 [===========>..................] - ETA: 0s - loss: 0.6305 - accuracy: 0.4081"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-e4f59091d13d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sgd'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m history=model.fit(x_train, tf.keras.utils.to_categorical(y_train),\n\u001b[0m\u001b[0;32m     10\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = pd.read_csv('09_DFN_x_train.csv')\n",
    "y = pd.read_csv('09_DFN_y_train.csv')\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,y,stratify=y)\n",
    "\n",
    "model = build_model()\n",
    "model.compile('sgd',loss = 'binary_crossentropy', metrics='accuracy')\n",
    "history=model.fit(x_train, tf.keras.utils.to_categorical(y_train),\n",
    "                 batch_size=200, epochs=1000,\n",
    "                 validation_data=(x_val,tf.keras.utils.to_categorical(y_val)),\n",
    "                 callbacks=[\n",
    "                     tf.keras.callbacks.EarlyStopping(patience=10, mode='min')  # 지난 no iter랑 똑같은 기능\n",
    "                 ]\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "from plotly import graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "from plotly import express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-0098eca2ace4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lines'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "fig=make_subplots(1,2,shared_xaxes=True)\n",
    "\n",
    "name='loss'\n",
    "fig.add_trace(go.Scatter(y=history.history[name],mode='lines',name=name),1,1)\n",
    "\n",
    "name='val_loss'\n",
    "fig.add_trace(go.Scatter(y=history.history[name],mode='lines',name=name),1,1)\n",
    "\n",
    "name='accuracy'\n",
    "fig.add_trace(go.Scatter(y=history.history[name],mode='lines',name=name),1,2)\n",
    "\n",
    "name='val_accuracy'\n",
    "fig.add_trace(go.Scatter(y=history.history[name],mode='lines',name=name),1,2)\n",
    "\n",
    "iplot(fig,show_link=True)\n",
    "# 학습안해서 그림 안나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(model.predict(x_train).argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer는 손실함수가 계산한 차이를 줄이는 방향으로 weights의 update를 지시하는 역활이다.  \n",
    "잔차를 단순반영하는 SGD부터 시작해 더 빠르게 차이를 개선하는 momentum, RMSProp, Adam등이 있다.  \n",
    "momentum과 RMSProp을 사용해보고 SGD와 비교하겠다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mom=build_model()\n",
    "model_mom.compile(tf.keras.optimizers.SGD(momentum=1),loss = 'binary_crossentropy',metrics='accuracy')\n",
    "history=model.fit(x_train, tf.keras.utils.to_categorical(y_train),\n",
    "                 batch_size=200, epochs=1000,\n",
    "                 validation_data=(x_val,tf.keras.utils.to_categorical(y_val)),\n",
    "                 callbacks=[\n",
    "                     tf.keras.callbacks.EarlyStopping(patience=20, mode='min')  # 지난 no iter랑 똑같은 기능\n",
    "                 ]\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rmsp=build_model()\n",
    "model_rmsp.compile('rmsprop',loss = 'binary_crossentropy',metrics='accuracy')\n",
    "history=model.fit(x_train, tf.keras.utils.to_categorical(y_train),\n",
    "                 batch_size=200, epochs=1000,\n",
    "                 validation_data=(x_val,tf.keras.utils.to_categorical(y_val)),\n",
    "                 callbacks=[\n",
    "                     tf.keras.callbacks.EarlyStopping(patience=10, mode='min')  # 지난 no iter랑 똑같은 기능\n",
    "                 ]\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = px.colors.qualitative.Vivid\n",
    "\n",
    "cols=['loss','val_loss','accuracy','val_accuracy']\n",
    "fig=make_subplots(2,2,shared_xaxes=True,column_titles=['Loss','Accuracy'],row_titles=['Training','Validation'])\n",
    "\n",
    "for n,col in enumerate(cols):\n",
    "    if n==0:\n",
    "        showleg=True\n",
    "    else:\n",
    "        showleg=False\n",
    "    fig.add_trace(go.Scatter(y=history.history[col][:50],\n",
    "                            mode='lines',name='SGD',legendgroup='SGD'.\n",
    "                            showlegend=showleg,\n",
    "                            marker=dict(color=colors[0])),n%2+1,n\\\\2+1)\n",
    "    fig.add_trace(go.Scatter(y=history.history[col][:50],\n",
    "                            mode='lines',name='Momentum',legendgroup='Momentum'.\n",
    "                            showlegend=showleg,\n",
    "                            marker=dict(color=colors[1])),n%2+1,n\\\\2+1)\n",
    "    fig.add_trace(go.Scatter(y=history.history[col][:50],\n",
    "                            mode='lines',name='RMSProp',legendgroup='RMSProp'.\n",
    "                            showlegend=showleg,\n",
    "                            marker=dict(color=colors[3])),n%2+1,n\\\\2+1)\n",
    "iplot(fig,show_link=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영상 보기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
